import tensorflow as tf
import streamlit as st
import pandas as pd
import numpy as np
import joblib
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(
    page_title="–ù–µ–π—Ä–æ—Å–µ—Ç–µ–≤–æ–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä",
    page_icon="üß†",
    layout="wide",
    initial_sidebar_state="expanded"
)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–µ—Å—Å–∏–∏
def init_session():
    session_defaults = {
        'model': None,
        'scaler': None,
        'encoders': None,
        'train_data': None,
        'target_col': None,
        'history': None,
        'feature_columns': None
    }
    for key, value in session_defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value

# –§—É–Ω–∫—Ü–∏—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö
def preprocess_data(df, target_column):
    try:
        if target_column not in df.columns:
            raise ValueError("–¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ –¥–∞–Ω–Ω—ã—Ö.")

        df_clean = df.copy()
        y = df_clean.pop(target_column)
        X = df_clean

        # –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        encoders = {}
        for col in X.select_dtypes(include=['object']).columns:
            encoders[col] = {v: k for k, v in enumerate(X[col].unique())}
            X[col] = X[col].map(encoders[col])

        # –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
        target_encoder = {v: k for k, v in enumerate(y.unique())}
        y = y.map(target_encoder)

        return X.astype('float32'), y.astype('float32'), encoders, target_encoder

    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)}")
        raise

# –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
def create_model(input_shape, n_classes, params):
    try:
        model = Sequential()

        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–∫—Ä—ã—Ç—ã—Ö —Å–ª–æ—ë–≤
        for _ in range(params['hidden_layers']):
            model.add(Dense(
                params['units'],
                activation=params['activation'],
                kernel_initializer='he_normal'
            ))
            if params['dropout'] > 0:
                model.add(Dropout(params['dropout']))

        # –í—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π
        if n_classes == 2:
            model.add(Dense(1, activation='sigmoid'))
            loss = 'binary_crossentropy'
        else:
            model.add(Dense(n_classes, activation='softmax'))
            loss = 'sparse_categorical_crossentropy'

        model.compile(
            optimizer=tf.keras.optimizers.Adam(learning_rate=params['lr']),
            loss=loss,
            metrics=['accuracy']
        )
        return model

    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –º–æ–¥–µ–ª–∏: {str(e)}")
        raise

# –û—Å–Ω–æ–≤–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
def main():
    init_session()

    st.title("üß† –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤–æ–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä")
    st.markdown("---")

    # –°–∞–π–¥–±–∞—Ä —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
    with st.sidebar:
        st.header("‚öôÔ∏è –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏")

        params = {
            'hidden_layers': st.slider("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∫—Ä—ã—Ç—ã—Ö —Å–ª–æ—ë–≤", 1, 5, 2),
            'units': st.slider("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–µ–π—Ä–æ–Ω–æ–≤ –≤ —Å–ª–æ–µ", 16, 256, 64),
            'activation': st.selectbox("–§—É–Ω–∫—Ü–∏—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏", ['relu', 'elu', 'tanh']),
            'dropout': st.slider("Dropout", 0.0, 0.5, 0.2),
            'lr': st.slider("Learning Rate", 0.0001, 0.01, 0.001, format="%.4f"),
            'epochs': st.slider("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö", 10, 200, 50),
            'batch_size': st.selectbox("–†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞", [32, 64, 128, 256])
        }

    # –û—Å–Ω–æ–≤–Ω—ã–µ –≤–∫–ª–∞–¥–∫–∏
    tab1, tab2, tab3 = st.tabs(["üìÅ –î–∞–Ω–Ω—ã–µ", "üéì –û–±—É—á–µ–Ω–∏–µ", "üîÆ –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ"])

    # –í–∫–ª–∞–¥–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    with tab1:
        st.header("–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö")

        uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV —Ñ–∞–π–ª", type="csv")

        if uploaded_file:
            try:
                df = pd.read_csv(uploaded_file)
                st.session_state.train_data = df

                st.success(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} –∑–∞–ø–∏—Å–µ–π")

                col1, col2 = st.columns(2)

                with col1:
                    st.subheader("–ü–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫")
                    st.dataframe(df.head())

                with col2:
                    st.subheader("–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞–Ω–Ω—ã—Ö")
                    st.write(f"**–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:** {df.shape[1]}")
                    st.write(f"**–¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö:**")
                    st.json(df.dtypes.astype(str).to_dict())

                    if st.button("–ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π"):
                        nulls = df.isnull().sum()
                        fig, ax = plt.subplots()
                        nulls[nulls > 0].plot(kind='bar', ax=ax)
                        ax.set_title("–ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è")
                        st.pyplot(fig)

            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {str(e)}")

    # –í–∫–ª–∞–¥–∫–∞ –æ–±—É—á–µ–Ω–∏—è
    with tab2:
        st.header("–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏")

        if st.session_state.train_data is not None:
            df = st.session_state.train_data
            target_col = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é", df.columns)

            if st.button("–ó–∞–ø—É—Å—Ç–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ", type="primary"):
                with st.spinner("–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏..."):
                    try:
                        # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
                        X, y, encoders, target_encoder = preprocess_data(df, target_col)

                        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è
                        st.session_state.encoders = {
                            'features': encoders,
                            'target': target_encoder
                        }

                        # –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ
                        scaler = StandardScaler()
                        X_scaled = scaler.fit_transform(X)
                        st.session_state.scaler = scaler
                        st.session_state.feature_columns = X.columns.tolist()

                        # –°–æ–∑–¥–∞–Ω–∏–µ –∏ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
                        n_classes = len(target_encoder)
                        model = create_model(X_scaled.shape[1], n_classes, params)

                        history = model.fit(
                            X_scaled, y,
                            epochs=params['epochs'],
                            batch_size=params['batch_size'],
                            validation_split=0.2,
                            verbose=0
                        )

                        st.session_state.model = model
                        st.session_state.history = history

                        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                        st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è")

                        col1, col2 = st.columns(2)

                        with col1:
                            st.metric("–§–∏–Ω–∞–ª—å–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å", f"{history.history['accuracy'][-1]:.2%}")
                            st.metric("–õ—É—á—à–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å –≤–∞–ª–∏–¥–∞—Ü–∏–∏", f"{max(history.history['val_accuracy']):.2%}")

                        with col2:
                            fig = plt.figure(figsize=(10, 4))
                            plt.plot(history.history['loss'], label='Train Loss')
                            plt.plot(history.history['val_loss'], label='Validation Loss')
                            plt.title('–ì—Ä–∞—Ñ–∏–∫ –ø–æ—Ç–µ—Ä—å')
                            plt.legend()
                            st.pyplot(fig)

                        st.success("–û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ!")

                    except Exception as e:
                        st.error(f"–û—à–∏–±–∫–∞: {str(e)}")
        else:
            st.warning("–°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ –Ω–∞ –≤–∫–ª–∞–¥–∫–µ üìÅ –î–∞–Ω–Ω—ã–µ")

    # –í–∫–ª–∞–¥–∫–∞ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è
    with tab3:
        st.header("–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö")

        if st.session_state.model:
            predict_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞", type="csv")

            if predict_file:
                try:
                    df_pred = pd.read_csv(predict_file)

                    if st.button("–í—ã–ø–æ–ª–Ω–∏—Ç—å –ø—Ä–æ–≥–Ω–æ–∑"):
                        with st.spinner("–ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö..."):
                            # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞
                            df_processed = df_pred.copy()

                            if st.session_state.target_col and st.session_state.target_col in df_processed.columns:
                                df_processed = df_processed.drop(columns=[st.session_state.target_col])

                            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è —Å—Ç–æ–ª–±—Ü–æ–≤
                            expected_columns = set(st.session_state.feature_columns)
                            missing_cols = expected_columns - set(df_processed.columns)
                            extra_cols = set(df_processed.columns) - expected_columns

                            if missing_cols:
                                st.error(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —Å—Ç–æ–ª–±—Ü—ã: {', '.join(missing_cols)}")
                                return

                            if extra_cols:
                                st.warning(f"–ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã: {', '.join(extra_cols)}")
                                df_processed = df_processed[list(expected_columns)]

                            for col, encoder in st.session_state.encoders['features'].items():
                                df_processed[col] = df_processed[col].apply(lambda x: encoder.get(x, -1))

                            non_numeric = df_processed.select_dtypes(exclude=[np.number]).columns
                            if not non_numeric.empty:
                                st.error(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –Ω–µ—á–∏—Å–ª–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ —Å—Ç–æ–ª–±—Ü–∞—Ö: {', '.join(non_numeric)}")
                                return

                            # –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –ø–æ—Ä—è–¥–∫–∞ —Å—Ç–æ–ª–±—Ü–æ–≤ –∫ –æ–∂–∏–¥–∞–µ–º–æ–º—É
                            df_processed = df_processed[st.session_state.feature_columns]

                            # –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ
                            X_pred = df_processed.astype('float32').values
                            X_scaled = st.session_state.scaler.transform(X_pred)

                            # –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ
                            predictions = st.session_state.model.predict(X_scaled)
                            inv_target = {v: k for k, v in st.session_state.encoders['target'].items()}

                            if predictions.shape[1] == 1:
                                results = [inv_target.get(int(round(p[0])), 'UNKNOWN') for p in predictions]
                                probs = [p[0] for p in predictions]
                            else:
                                results = [inv_target.get(np.argmax(p), 'UNKNOWN') for p in predictions]
                                probs = [np.max(p) for p in predictions]

                            result_df = pd.DataFrame({
                                '–ü—Ä–æ–≥–Ω–æ–∑': results,
                                '–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å': probs
                            }).style.format({'–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å': '{:.2%}'})

                            st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è")
                            st.dataframe(result_df, height=400)

                except Exception as e:
                    st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è: {str(e)}")
                    st.error(f"–ü—Ä–æ–±–ª–µ–º–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:\n{df_pred.dtypes}\n–ü—Ä–∏–º–µ—Ä —Å—Ç—Ä–æ–∫–∏:\n{df_pred.iloc[0]}")
        else:
            st.warning("–°–Ω–∞—á–∞–ª–∞ –æ–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å –Ω–∞ –≤–∫–ª–∞–¥–∫–µ üéì –û–±—É—á–µ–Ω–∏–µ")

if __name__ == "__main__":
    main()
